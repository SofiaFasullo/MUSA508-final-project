---
title: "Final Project"
author: "Michael Dunst & Sofia Fasullo"
date: "`r Sys.Date()`"
output:
  html_document:
    code_folding: hide
    toc: true
    toc_float: true
knit: (function(input, encoding) {
    rmarkdown::render(
      input = input,
      encoding = encoding,
      envir = globalenv()
    )
  })    
---
**Project Description**: Airbnb has become a giant in the hospitality industry by offering ordinary property owners a chance to cash in on their home by renting it out by the night. We came forward to create a more helpful model than Airbnb currently provides to give prospective hosts an accurate forecast of what their home could be worth to a jetsetting visitor.

By creating this model, then packaging it in an easy to use app called MyAirRate, homeowners can easily input their home's attributes and get an estimate. We, on the other hand, will quickly become a vital part of Airbnb's business and be a ripe target for acquisition and buyout.

```{r setup, echo=FALSE, install= TRUE, cache=TRUE, message=FALSE, results=FALSE}
knitr::opts_chunk$set(echo = TRUE, message=FALSE, warning=FALSE)
# Load some libraries
rm(list = ls())
library(tidycensus)
library(dplyr)
library(viridis)
library(tidyverse)
library(sf)
library(spdep)
library(caret)
library(ckanr)
library(FNN)
library(grid)
library(gridExtra)
library(ggcorrplot) # plot correlation plot
library(corrr)      # another way to plot correlation plot
library(kableExtra)
library(jtools)     # for regression model plots
library(ggstance) # to support jtools plots
library(ggpubr)    # plotting R^2 value on ggplot point scatter
library(broom.mixed) # needed for effects plots
library(stargazer)
library(readr)
library(lubridate)
options(scipen=999) #scientific notation off

# Functions and data directory
census_api_key("8c8e36c4b5046c4d7f8a5d9f0f7a7d0ddde86e8b")

root.dir = "https://raw.githubusercontent.com/urbanSpatial/Public-Policy-Analytics-Landing/master/DATA/"

source("https://raw.githubusercontent.com/urbanSpatial/Public-Policy-Analytics-Landing/master/functions.r")

palette5 <- c("#981FAC","#CB0F8B","#FF006A","#FE4C35","#FE9900")
palette4 <- c("#981FAC","#FF006A","#FE4C35","#FE9900")
palette2 <- c("#981FAC","#FF006A")

```

###Data Collection and Exploration

To understand the intricacies of the Airbnb housing price trends, MyAirRate sourced a dataset of 2018 Airbnb prices in Amsterdam, capital of the Netherlands. We observed the features of Airbnb units (such as number of rooms, location) that appeared to be correlated to high prices to create our accurate model - but before doing that, we had to make sure our data was easy to work with, and that required some formatting technicalities.

```{r import listings}

listings <- read_csv("https://github.com/SofiaFasullo/MUSA508-final-project/raw/main/listings.csv")

listing_details <- read_csv("https://github.com/SofiaFasullo/MUSA508-final-project/raw/main/listings_details.csv")
```

```{r clean_data cache=TRUE}

listing_details <- listing_details %>%
  select(1,23,26,29,39,40,49,50,52:57,60,61,80,96)

listings <- listings %>%
  select(1)

full_listings <- merge(listings,listing_details,by="id")

full_listings <- full_listings %>% mutate(price = price %>% str_remove_all("[$,]") %>% as.numeric())

full_listings.sf <- st_as_sf(full_listings,coords=c("longitude","latitude"),crs=4326)
```

At first, we looked at a few sets of attributes to get a general sense of how different variables associate with each other.

One of the stronger correlations is between user experience and nightly rate. One might notice that a prospective host wouldn't have a user experience score to incorporate into a prediction, but we'll come back to that.

The next chart compares bedrooms and price. Unlike in a typical housing market, these is no continuous upward trend as the number of bedrooms increases. Perhaps this is due to the fact that center city apartments tend to be smaller yet more desirable.

Next, looking at responsiveness, there again isn't a clear trend, except maybe a correlation between higher prices and longer response times.

Lastly, we looked at the makeup of real estate and found an overwhelming portion of Airbnbs are "apartments". Looking at the average rate by home type, though, there were no interesting findings except for the price premium to stay in a lighthouse!

```{r data_exploration, cache = TRUE, message = FALSE, warning = FALSE}
ggplot(full_listings, aes(review_scores_rating,price))+
  geom_jitter(height=1,width=1)+
  xlim(50,100)+
  ylim(0,1000)+
  labs(x="User Ratings", y="Nightly Rate",
             title = "User Experience vs. Price",
             subtitle = "Amsterdam Airbnbs")+ 
  theme_minimal()
#General increase in price as ratings go up.
  
ggplot(full_listings, aes(bedrooms,price))+ 
  geom_bar(position = "dodge", stat = "summary", fun = "mean", fill="darkgreen")+
  labs(x="Bedrooms", y="Nightly Rate",
             title = "Number of Bedrooms vs. Price",
             subtitle = "Amsterdam Airbnbs")+ 
  theme_minimal()
#No general trend by number of bedrooms.

full_listings %>%
  drop_na(host_response_time) %>% #This drop na isn't working as intended
ggplot(., aes(host_response_time,price))+ 
  geom_bar(position = "dodge", stat = "summary", fun = "mean", fill="darkgreen")+
  labs(x="Host response time", y="Nightly Rate",
             title = "Host Eagerness to Rent vs. Price",
             subtitle = "Amsterdam Airbnbs")+ 
  theme_minimal()
#No association between responsiveness and nightly rate.

full_listings %>% 
	group_by(property_type) %>% 
	summarise(count = n()) %>% 
	ggplot(aes(x = reorder(property_type,(count)), y = count)) + 
		geom_bar(stat = 'identity', fill="darkgreen") + 
		theme_minimal()+
  scale_y_log10()+
  labs(x="Property Type", y="Count (Log-scaled)",
             title = "Types of Airbnb Properties",
             subtitle = "Amsterdam")+
  coord_flip()

ggplot(full_listings, aes(property_type,price))+ 
  geom_bar(position = "dodge", stat = "summary", fun = "mean", fill="darkgreen")+
  labs(x="Property Type", y="Nightly Rate",
             title = "Type of Property vs. Price",
             subtitle = "Amsterdam Airbnbs")+
  coord_flip()+
  theme_minimal()
#Nothing sticks out...except lighthouses!
```

To get a general sense of the city of Amsterdam, this is a map of the neighborhoods that each property is categorized into.

```{r new_features, cache = TRUE, message = FALSE, warning = FALSE}
AMS_neighborhoods.sf <- 
  st_read("https://github.com/SofiaFasullo/MUSA508-final-project/raw/main/neighbourhoods.geojson")

ggplot() +
  geom_sf(data = AMS_neighborhoods.sf, aes(fill=neighbourhood))+
  labs(title = "Amsterdam Neighborhoods")+
  theme_minimal()
```

```{r monuments, cache = TRUE, message = FALSE, warning = FALSE}
monuments.sf <- st_read("https://github.com/SofiaFasullo/MUSA508-final-project/raw/main/landmarks.json")

#Change CRS to meters
full_listings.sf <- st_transform(full_listings.sf, crs = "EPSG:28992")
AMS_neighborhoods.sf <- st_transform(AMS_neighborhoods.sf, crs = "EPSG:28992")
monuments.sf <- st_transform(monuments.sf, crs = "EPSG:28992")

full_listings.sf <-
  full_listings.sf %>% 
    mutate(
      monuments_nn3 = nn_function(st_coordinates(full_listings.sf), 
                              st_coordinates(monuments.sf), k = 3))
```

Airbnb tends to be popular with tourists who are likely to pay more to stay close to what they want to visit. So, we brought in the locations of the top 20 landmarks in Amsterdam in order to rate each property's ease of access to where people want to go.

As you can see, there is a strong negative correlation between average distance to the nearest three landmarks and nightly rate.

```{r graph_monuments_data, cache = TRUE, message = FALSE, warning = FALSE}
ggplot()+
  geom_sf(data = AMS_neighborhoods.sf, fill="gray90")+
  geom_sf(data=monuments.sf, color="darkgreen")+
  ggtitle("Top 20 Landmarks", subtitle = "Amsterdam, Netherlands") +
  theme_minimal()

ggplot(full_listings.sf, aes(monuments_nn3,price))+
  geom_jitter(height=0.5,width=0.5)+
  xlim(0,7500)+
  ylim(0,1000)+
  labs(x="Avg. Distance to 3 Landmarks (m)", y="Nightly Rate",
             title = "Location vs. Price",
             subtitle = "Amsterdam Airbnbs")+ 

  geom_point(data=full_listings.sf,mapping=aes(monuments_nn3,price))+
  geom_smooth(method="lm")+
  stat_cor(method="pearson",
           label.x=4500,
           label.y=950) +
  labs(x="Distance From Monuments", y="Nightly Rate",
             title = "Monuments in Vicinity vs. Price",
             subtitle = "Amsterdam Airbnbs")+
  theme_minimal()
```

## Data Engineering

Regression models assume that the data being put into them is normally distributed, meaning that the majority of the data is an average value, with some higher and some lower values. However, when we look at Airbnb prices, most Airbnbs have lower prices, with an average of about \$152 per night, while very few have very high prices, up to \$8,500 per night. To make our data more useful and applicable to this assumption, we can transform it by taking the mathematical log of price to find a normal distribution. Since we are sticking true to the mathematical assumption, we can trust our model to be more accurate and reliable.

``` {r transform_variable, cache = TRUE, message = FALSE, warning = FALSE}
max(full_listings.sf$price)
mean(full_listings.sf$price)

ggplot()+
  geom_histogram(data=full_listings.sf,mapping=aes(price)) +
  labs(x="Nightly Rate", y="Frequency",
             title = "Distribution of Nightly Rate Prices",
             subtitle = "Amsterdam Airbnbs")+
  theme_minimal()

ggplot()+
  geom_histogram(data=full_listings.sf,mapping=aes(log10(price))) +
  labs(x="Nightly Rate", y="Frequency",
             title = "Distribution of Logarithmic Transformation",
             subtitle = "Amsterdam Airbnbs")+
  theme_minimal()

#clearly, taking the log of price normalizes the variable, wwhich is an assumption of regression models

#create a new variable of the log of price
full_listings.sf = full_listings.sf %>% mutate(
  logPrice = log10(price)
)
```

Another piece of feature engineering is turning the host's join date into simply a year. Before, the data of the exact day a host started with Airbnb,which was totally different for every host! This was not helpful for us because we wanted to see trends, so we switched the data just to the year a host joined Airbnb. This way, we could compare how many years hosts have been active and if that raises their property prices.

Also, looking at the relationship between Airbnb host experience and user reviews, we can see that newer hosts achieve lower rates than longer-tenured ones. Using this correlation, we can use an assumption for prospective hosts that they will have a lesser rating. So when a new host joins Airbnb and wants to check their MyAirRate, it's not a problem if they don't have existing reviews to input to our model - our model will assume a default, lower review.

```{r extract_year_from_date, cache = TRUE, message = FALSE, warning = FALSE }
length(unique(full_listings.sf$host_since))
#this variable is different for every observation so it is not meaningful, simplifying it to year would be more helpful

full_listings.sf = full_listings.sf %>% mutate(
  year = lubridate::year(host_since)
)

#full_listings.sf = full_listings.sf %>% mutate(
#  superhost = ifelse(host_is_superhost=="t",1,0),
#  year = as.numeric(format(as.Date(full_listings.sf$host_since, format="%Y/%m/%d"),"%Y")))

ggplot(full_listings.sf, aes(year,review_scores_rating))+
  geom_jitter(height=1,width=1)+
#  xlim(50,100)+
#  ylim(0,1000)+
  labs(x="Year Joined", y="User Ratings",
             title = "Host Experience vs. Visitor Rating",
             subtitle = "Amsterdam Airbnbs")+ 
  theme_minimal()

```

#Fitting a "Kitchen Sink" Model

MyAirRate began the process of tuning an accurate model by just putting all the data together that we had and seeing how it can mathematically predict price. We used an ordinary least squares model that assumes that each variable (ie number of bedrooms) can be linearly related to Airbnb price. Putting all this data together is often called a "kitchen sink" model, and it is a good place to start.

To test our model, we split our Amsterdam Airbnb dataset into two datasets. One group of Airbnbs will have all their information fed into a model generator that sees their relationship to price. Then a model will be created, and we'll test it on the second dataset we had set aside.
```{r partion_data, cache = TRUE, message = FALSE, warning = FALSE }
#split dataset into training and testing before fitting regression model

set.seed(111)
train = createDataPartition(y=full_listings.sf$logPrice, times = 1, p = 0.5, list=FALSE)
listings_train = full_listings.sf[train,]
listings_test = full_listings.sf[-train,]
```

```{r kitchen_sink_model, cache = TRUE, message = FALSE, warning = FALSE }

#because there are so many variables it would take up lots of space to display the whole summary, so we will just display the important parts in a table comparing models

#neighborhood has too many NAs, and price is directly correlated to logPrice

fullOLS.lm = lm(logPrice~.,data= dplyr :: select(listings_train,-c(host_since, neighbourhood, price)) %>% st_drop_geometry() %>%  na.omit())

summary_fullOLS = summary(fullOLS.lm)
stargazer(data=fullOLS.lm, type="text", title = "Summary Statistics for Kitchen-Sink Model")

```


#Assessing Which Variables to Use

The "kitchen sink" model uses every feature present in the dataset, but they may not all be necessary. For example, if an Airbnb has an extra bedroom, it probably has an extra bed, so number of beds would be redundant info. These features are correlated, and having these in your model is called having collinearity, which is unwanted. Also, some features might not be closely correlated with price. Looking at how features correlate with each other and price is a helpful way to pick out the best features for our model.

```{r corr_table, cache = TRUE, message = FALSE, warning = FALSE}
numericVars <- select_if(st_drop_geometry(full_listings.sf), is.numeric) %>% na.omit()

ggcorrplot(
  round(cor(numericVars), 1),
  p.mat = cor_pmat(numericVars),
  colors = c("deepskyblue", "grey100", "firebrick1"),
  type="lower",
  insig = "blank") +  
    labs(title = "Correlation Matrix of Numeric Variables", tl.cex = 0.5, tl.col = "black") +
  plotTheme()

```

#Fitting Models based on Selective Variables

This model has fewer variables, removing the redundant variables. We can see that the mathematical diagnostics are worse for this model; we have a lower R^2 value and higher error. This means the model is less close to predicting correct prices and less of the variation in price is caught byt the model. However, we will not scrap the model just yet. First, we will tweak it to add new features. Lastly, we see that our "kitchen sink" model is great to predict prices in Amsterdam, but what about in other cities? Because there is so much information in that model, it could be over-tailored to data in Amsterdam. A more minimal model might be worse at predicting exact prices in Amsterdam, but it could be that it just uses the variables that are truly powerful in most cases. Also, consider this data is from 2018. We do not need to extremely accurately predic 2018 rates anymore! We need a dataset that is consistent for future years and across different cities.
```{r selective_model, cache = TRUE, message = FALSE, warning = FALSE }

trimmedOLS.lm = lm(logPrice~host_response_time+host_is_superhost+neighbourhood_cleansed+bedrooms+review_scores_rating+reviews_per_month+monuments_nn3+year, data=st_drop_geometry(listings_train) %>% drop_na())

summary_trimmedOLS = summary(trimmedOLS.lm)

stargazer(data=trimmedOLS.lm, type="text", title = "Summary Statistics for Model Based on Selected Variables", coef.omit="none")
#result: trying to use only the variables we think are good makes the R^2 drop a lot
```


#Spatial Clustering of Price - the "Secret Sauce" to a Model

MyAirRate creators are based at the University of Pennsylvania's Master of Urban Spatial Analytics Program to research spatial effects of trends. With robust research to inform our approach, we decided to look at geographic trends of prices. Airbnb owners with high prices are likely located near other Airbnb owners with high prices. We created a feature called "lagPrice" which means the average price of the nearest 5 properties in the area.

You can see from our map of average price per neighborhood that higher priced Airbnbs are located in the center of Amsterdam. This may be due to monuments and tourist attractions there, which we have already accounted for. This spatial lag of price creates a higher-resolution method to pick up little complexities and outside "hot spots".
```{r nearest_neighbor, cache = TRUE, message = FALSE, warning = FALSE }
#basic understanding of price distribution

#aggregate price by neighborhood instead
AMS_neighborhoods.sf = full_listings.sf %>% 
  group_by(neighbourhood_cleansed) %>% 
  summarize(avg_price_nhood = mean(price)) %>% 
  st_drop_geometry() %>% 
  right_join(.,AMS_neighborhoods.sf, by=c("neighbourhood_cleansed"="neighbourhood"))

palette5.2 <- c("#d7191c",
"#fdae61",
"#ffffbf",
"#a6d96a",
"#1a9641")

ggplot() +
  geom_sf(data = AMS_neighborhoods.sf , aes(fill=q5(avg_price_nhood), geometry = geometry))+
  scale_fill_manual(values = rev(palette5.2),
                   labels=qBr(AMS_neighborhoods.sf,"avg_price_nhood"),
                   name="Quintile\nBreaks")+
  labs(title="Nightly Rate by Neighborhood", subtitle="Amsterdam Airbnbs") +
  theme_minimal()
  #not sure why this isn't working
  
  
```
We can see that the average Airbnb price of the nearest 5 Airbnbs is strongly and significantly coordinated with the price of a specific Airbnb. This encourages us to use our lagPrice feature in our model.

```{r map_lagPrice, cache = TRUE, message = FALSE, warning = FALSE }
coords <- st_coordinates(full_listings.sf) 

neighborList <- knn2nb(knearneigh(coords, 5)) #5 nearest neighbors

spatialWeights <- nb2listw(neighborList, style="W")

full_listings.sf$lagPrice <- lag.listw(spatialWeights, full_listings.sf$price) 

ggplot(data=full_listings.sf,mapping = aes(x=lagPrice,y=price)) + 
  geom_point() + geom_smooth(method="lm") + stat_cor(method="pearson") +
  xlim(0,1500) + ylim(0,1500)+
  labs(x="Spatial Lag of Price", y="Price",
             title = "Spatial Correlation of Nightly Rate Price",
             subtitle = "Amsterdam Airbnbs")+
  theme_minimal()

```
Our model that includes spatial lag of price still does worse than our "kitchen sink" model, but again we will look at how consistent this model.
```{r model_spatial_lag, cache = TRUE, message = FALSE, warning = FALSE }
set.seed(111)
listings_train = full_listings.sf[train,]
listings_test = full_listings.sf[-train,]

#fully listed out all the variables because we need to take the log of spatial lag of price
smarter_model = lm(logPrice ~ log10(lagPrice)+host_response_time+host_is_superhost+neighbourhood_cleansed+bedrooms+review_scores_rating+reviews_per_month+monuments_nn3+year, data=st_drop_geometry(drop_na(listings_train)))

stargazer(data=smarter_model, type="text", title = "Summary Statistics for Model Using Spatial Lag of Price")
```

```{r kitchen_sink_spatial_model, cache = TRUE, message = FALSE, warning = FALSE }
#kitchen sink with log of price
smarter_model2 = lm(logPrice ~host_response_time+host_is_superhost+neighbourhood_cleansed+property_type+room_type+accomodates+bathrooms+bedrooms+beds+square_feet+review_scores_rating+reviews_per_month+monunements_nn3+log(lagPrice)+year,data=st_drop_geometry(listings_train))

stargazer(data=smarter_model2,type="text", title = "Summary Statistics for Model Using Spatial Lag of Price-Kitchen Sink")
```

#Diagnostics for Generalizability and Accuracy

Our model's accuracy can be described as how closely our model predicts Airbnb prices on our test dataset, whereas our model's generalizability can be described as how consistently our model predicts Airbnb prices generally over many different datasets. We only have the one Amsterdam dataset, so we test for accuracy by seeing how well our model predicts on our "testing" dataset that we set aside while creating the model. We imitate the effect of multiple different datasets by doing a mathematical process called cross-validation, where we split "training" and "testing" datasets multiple times, and see how consistent our model is across multiple different "test" datasets.

Our dataset is from Amsterdam and was collected in 2018, but we want MyAirRate to be consistent in multiple cities and over many years, so for this reason, we care more about generalizability. You can see that our first model has a higher R^2 value, which means it more of the price variation is explained by our first model, the "kitchen sink model". However, our final model has a lower mean absolute error across cross-validation datasets. Mean absolute error (MAE) is how we test accuracy on a test dataset - it takes the absolute distance from the true price of overestimated price and underestimated price and then the average. We chose not to use percent error (percent of total price) because we feel that absolute error is easier to understand. A new MyAirRate user would understand $47 error range better than 10%, for example.
```{r diagnostics, cache = TRUE, message = FALSE, warning = FALSE }
#smarter_model seems like our best bet
#accuracy test: error for test dataset
MSE = mean((exp(listings_test$logPrice) - exp(predict(smarter_model,data=st_drop_geometry(drop_na(select(listings_train,-price))))))^2)
#MSE #6 mean square error is pretty good?!
MAE = mean(abs(exp(listings_test$logPrice) - exp(predict(smarter_model,data=st_drop_geometry(drop_na(select(listings_train,-price)))))))
MAE

#vs our model without the secret sauce
MSE_1stmod = mean((exp(listings_test$logPrice) - exp(predict(fullOLS.lm,data=st_drop_geometry(drop_na(select(listings_train,-c(price,lagPrice))))))^2))
#MSE_1stmod
MAE_1stmod = mean(abs(exp(listings_test$logPrice) - exp(predict(fullOLS.lm,data=st_drop_geometry(drop_na(select(listings_train,-c(price,lagPrice))))))))
MAE_1stmod
#first model with no data engineering and variable selection is better with accuracy BUT


#generalizability test 

fitControl <- trainControl(method = "cv", number = 100)
set.seed(825)

reg.cv <- 
  train(price~ ., data = st_drop_geometry(full_listings.sf) %>%                       dplyr::select(lagPrice,host_response_time,host_is_superhost,neighbourhood_cleansed,bedrooms,review_scores_rating,reviews_per_month,price) %>% na.omit(), 
     method = "lm", trControl = fitControl, na.action = na.omit)

reg.cv


first.cv <- 
  train(price ~ ., data = st_drop_geometry(full_listings.sf) %>%                                dplyr::select(-c(logPrice,lagPrice)) %>% drop_na(), 
     method = "lm", trControl = fitControl, na.action = na.pass)
first.cv

#so cross validation R^2 accuracy is better in the first model with more predictors but the error of the cross validated tests is lower for our tuned model, so we are favoring slightly less accuracy to higher generalizability
```























