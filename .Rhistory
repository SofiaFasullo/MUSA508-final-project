knitr::opts_chunk$set(echo = TRUE, message=FALSE, warning=FALSE)
# Load some libraries
rm(list = ls())
library(tidycensus)
library(dplyr)
library(viridis)
library(tidyverse)
library(sf)
library(spdep)
library(caret)
library(ckanr)
library(FNN)
library(grid)
library(gridExtra)
library(ggcorrplot) # plot correlation plot
library(corrr)      # another way to plot correlation plot
library(kableExtra)
library(jtools)     # for regression model plots
library(ggstance) # to support jtools plots
library(ggpubr)    # plotting R^2 value on ggplot point scatter
library(broom.mixed) # needed for effects plots
library(stargazer)
library(readr)
library(lubridate)
options(scipen=999) #scientific notation off
# Functions and data directory
census_api_key("8c8e36c4b5046c4d7f8a5d9f0f7a7d0ddde86e8b")
root.dir = "https://raw.githubusercontent.com/urbanSpatial/Public-Policy-Analytics-Landing/master/DATA/"
source("https://raw.githubusercontent.com/urbanSpatial/Public-Policy-Analytics-Landing/master/functions.r")
palette5 <- c("#981FAC","#CB0F8B","#FF006A","#FE4C35","#FE9900")
palette4 <- c("#981FAC","#FF006A","#FE4C35","#FE9900")
palette2 <- c("#981FAC","#FF006A")
listings <- read_csv("https://github.com/SofiaFasullo/MUSA508-final-project/raw/main/listings.csv")
listing_details <- read_csv("https://github.com/SofiaFasullo/MUSA508-final-project/raw/main/listings_details.csv")
listing_details <- listing_details %>%
select(1,23,26,29,39,40,49,50,52:57,60,61,80,96)
listings <- listings %>%
select(1)
full_listings <- merge(listings,listing_details,by="id")
full_listings <- full_listings %>% mutate(price = price %>% str_remove_all("[$,]") %>% as.numeric())
full_listings.sf <- st_as_sf(full_listings,coords=c("longitude","latitude"),crs=4326)
AMS_neighborhoods.sf <-
st_read("https://github.com/SofiaFasullo/MUSA508-final-project/raw/main/neighbourhoods.geojson")
monuments.sf <- st_read("https://github.com/SofiaFasullo/MUSA508-final-project/raw/main/landmarks.json")
#Change CRS to meters
full_listings.sf <- st_transform(full_listings.sf, crs = "EPSG:28992")
AMS_neighborhoods.sf <- st_transform(AMS_neighborhoods.sf, crs = "EPSG:28992")
monuments.sf <- st_transform(monuments.sf, crs = "EPSG:28992")
full_listings.sf <-
full_listings.sf %>%
mutate(
monuments_nn3 = nn_function(st_coordinates(full_listings.sf),
st_coordinates(monuments.sf), k = 3))
#create a new variable of the log of price
full_listings.sf = full_listings.sf %>% mutate(
logPrice = log10(price)
)
length(unique(full_listings.sf$host_since))
#this variable is different for every observation so it is not meaningful, simplifying it to year would be more helpful
full_listings.sf = full_listings.sf %>% mutate(
year = lubridate::year(host_since)
)
#full_listings.sf = full_listings.sf %>% mutate(
#  superhost = ifelse(host_is_superhost=="t",1,0),
#  year = as.numeric(format(as.Date(full_listings.sf$host_since, format="%Y/%m/%d"),"%Y")))
#split dataset into training and testing before fitting regression model
set.seed(111)
train = createDataPartition(y=full_listings.sf$logPrice, times = 1, p = 0.5, list=FALSE)
listings_train = full_listings.sf[train,]
listings_test = full_listings.sf[-train,]
#because there are so many variables it would take up lots of space to display the whole summary, so we will just display the important parts in a table comparing models
#host_since and monuments_nn3 are not useful, neighborhood has too many NAs, and price is directly correlated to logPrice
fullOLS.lm = lm(logPrice~.,data= dplyr :: select(listings_train,-c(host_since, neighbourhood, monuments_nn3, price)) %>% st_drop_geometry() %>%  na.omit())
summary_fullOLS = summary(fullOLS.lm)
stargazer(data=fullOLS.lm, type="text", title = "Summary Statistics for Kitchen-Sink Model")
#the model based on our diagnostics that would be useful
#the way we calculated n made it perfectly collinear with the neighborhood, wwhich is not helpful for us
trimmedOLS.lm = lm(logPrice~host_response_time+host_is_superhost+neighbourhood_cleansed+bedrooms+review_scores_rating+reviews_per_month+monuments_nn3+year, data=st_drop_geometry(listings_train) %>% drop_na())
summary_trimmedOLS = summary(trimmedOLS.lm)
stargazer(data=trimmedOLS.lm, type="text", title = "Summary Statistics for Model Based on Selected Variables", coef.omit="none")
#result: trying to use only the variables we think are good makes the R^2 drop a lot
#aggregate price by neighborhood instead
AMS_neighborhoods.sf = full_listings.sf %>%
group_by(neighbourhood_cleansed) %>%
summarize(avg_price_nhood = mean(price)) %>%
st_drop_geometry() %>%
right_join(.,AMS_neighborhoods.sf, by=c("neighbourhood_cleansed"="neighbourhood"))
palette5.2 <- c("#d7191c",
"#fdae61",
"#ffffbf",
"#a6d96a",
"#1a9641")
coords <- st_coordinates(full_listings.sf)
neighborList <- knn2nb(knearneigh(coords, 5)) #5 nearest neighbors
neighborList <- knn2nb(knearneigh(coords, 5)) #5 nearest neighbors
spatialWeights <- nb2listw(neighborList, style="W")
full_listings.sf$lagPrice <- lag.listw(spatialWeights, full_listings.sf$price)
set.seed(111)
listings_train = full_listings.sf[train,]
listings_test = full_listings.sf[-train,]
smarter_model = lm(logPrice ~ log10(lagPrice)+host_response_time+host_is_superhost+neighbourhood_cleansed+bedrooms+review_scores_rating+reviews_per_month+monuments_nn3+year, data=st_drop_geometry(drop_na(listings_train)))
stargazer(data=smarter_model, type="text", title = "Summary Statistics for Model Using Spatial Lag of Price")
#kitchen sink with log of price
smarter_model2 = lm(logPrice ~., data=st_drop_geometry(drop_na(select(listings_train,-price))))
summary(smarter_model)
#smarter_model seems like our best bet
#accuracy test: error for test dataset
MSE = mean((exp(listings_test$logPrice) - exp(predict(smarter_model,data=st_drop_geometry(drop_na(select(listings_train,-price))))))^2)
#MSE #6 mean square error is pretty good?!
MAE = mean(abs(exp(listings_test$logPrice) - exp(predict(smarter_model,data=st_drop_geometry(drop_na(select(listings_train,-price)))))))
MAE
#vs our model without the secret sauce
MSE_1stmod = mean((exp(listings_test$logPrice) - exp(predict(fullOLS.lm,data=st_drop_geometry(drop_na(select(listings_train,-c(price,lagPrice))))))^2))
#MSE_1stmod
MAE_1stmod = mean(abs(exp(listings_test$logPrice) - exp(predict(fullOLS.lm,data=st_drop_geometry(drop_na(select(listings_train,-c(price,lagPrice))))))))
MAE_1stmod
#first model with no data engineering and variable selection is better with accuracy BUT
#generalizability test
fitControl <- trainControl(method = "cv", number = 100)
set.seed(825)
reg.cv <-
train(price~ ., data = st_drop_geometry(full_listings.sf) %>%                       dplyr::select(lagPrice,host_response_time,host_is_superhost,neighbourhood_cleansed,bedrooms,review_scores_rating,reviews_per_month,price) %>% na.omit(),
method = "lm", trControl = fitControl, na.action = na.omit)
reg.cv
first.cv <-
train(price ~ ., data = st_drop_geometry(full_listings.sf) %>%                                dplyr::select(-c(logPrice,lagPrice)) %>% drop_na(),
method = "lm", trControl = kfolds, na.action = na.pass)
first.cv
first.cv <-
train(price ~ ., data = st_drop_geometry(full_listings.sf) %>%                                dplyr::select(-c(logPrice,lagPrice)) %>% drop_na(),
method = "lm", trControl = kfolds, na.action = na.pass)
first.cv <-
train(price ~ ., data = st_drop_geometry(full_listings.sf) %>%                                dplyr::select(-c(logPrice,lagPrice)) %>% drop_na(),
method = "lm", trControl = fitControl, na.action = na.pass)
first.cv <-
train(price ~ ., data = st_drop_geometry(full_listings.sf) %>%                                dplyr::select(-c(logPrice,lagPrice)) %>% drop_na(),
method = "lm", trControl = fitControl, na.action = na.pass)
first.cv
reg.cv
first.cv
names(listings)
ggplot(full_listings, aes(review_scores_rating,price))+
geom_jitter(height=1,width=1)+
xlim(50,100)+
ylim(0,1000)+
labs(x="User Ratings", y="Nightly Rate",
title = "User Experience vs. Price",
subtitle = "Amsterdam Airbnbs")+
theme_minimal()
ggplot(full_listings.sf, aes(review_scores_rating,year))+
geom_jitter(height=1,width=1)+
#  xlim(50,100)+
#  ylim(0,1000)+
labs(x="User Ratings", y="Nightly Rate",
title = "User Experience vs. Price",
subtitle = "Amsterdam Airbnbs")+
theme_minimal()
ggplot(full_listings.sf, aes(year,review_scores_rating))+
geom_jitter(height=1,width=1)+
#  xlim(50,100)+
#  ylim(0,1000)+
labs(x="User Ratings", y="Nightly Rate",
title = "User Experience vs. Price",
subtitle = "Amsterdam Airbnbs")+
theme_minimal()
unique(full_listings.sf$year)
ggplot(full_listings, aes(bedrooms,price))+
geom_bar(position = "dodge", stat = "summary", fun = "mean", fill="darkgreen")+
labs(x="Bedrooms", y="Nightly Rate",
title = "Number of Bedrooms vs. Price",
subtitle = "Amsterdam Airbnbs")+
theme_minimal()
full_listings %>%
drop_na(host_response_time) %>% #This drop na isn't working as intended
ggplot(., aes(host_response_time,price))+
geom_bar(position = "dodge", stat = "summary", fun = "mean", fill="darkgreen")+
labs(x="Host response time", y="Nightly Rate",
title = "Host Eagerness to Rent vs. Price",
subtitle = "Amsterdam Airbnbs")+
theme_minimal()
full_listings %>%
group_by(property_type) %>%
summarise(count = n()) %>%
ggplot(aes(x = reorder(property_type,(count)), y = count)) +
geom_bar(stat = 'identity', fill="darkgreen") +
theme_minimal()+
scale_y_log10()+
labs(x="Property Type", y="Count (Log-scaled)",
title = "Types of Airbnb Properties",
subtitle = "Amsterdam")+
coord_flip()
ggplot(full_listings, aes(property_type,price))+
geom_bar(position = "dodge", stat = "summary", fun = "mean", fill="darkgreen")+
labs(x="Property Type", y="Nightly Rate",
title = "Type of Property vs. Price",
subtitle = "Amsterdam Airbnbs")+
coord_flip()+
theme_minimal()
ggplot() +
geom_sf(data = AMS_neighborhoods.sf, aes(fill=neighbourhood))
AMS_neighborhoods.sf <-
st_read("https://github.com/SofiaFasullo/MUSA508-final-project/raw/main/neighbourhoods.geojson")
ggplot() +
geom_sf(data = AMS_neighborhoods.sf, aes(fill=neighbourhood))
ggplot() +
geom_sf(data = AMS_neighborhoods.sf, aes(fill=neighbourhood))+
labs(title = "Amsterdam Neighborhoods")+
theme_minimal()
ggplot()+
geom_sf(data = AMS_neighborhoods.sf, fill="gray90")+
geom_sf(data=monuments.sf, color="darkgreen")+
ggtitle("Top 20 Landmarks", subtitle = "Amsterdam, Netherlands") +
theme_minimal()
ggplot(full_listings.sf, aes(monuments_nn3,price))+
geom_jitter(height=0.5,width=0.5)+
geom_smooth(method="lm")+
stat_cor(method="pearson",
label.x=4500,
label.y=950) +
xlim(0,7500)+
ylim(0,1000)+
labs(x="Avg. Distance to 3 Landmarks (m)", y="Nightly Rate",
title = "Location vs. Price",
subtitle = "Amsterdam Airbnbs")+
geom_point(data=full_listings.sf,mapping=aes(monuments_nn3,price))+
labs(x="Distance From Monuments", y="Nightly Rate",
title = "Monuments in Vicinity vs. Price",
subtitle = "Amsterdam Airbnbs")+
theme_minimal()
ggplot(full_listings.sf, aes(monuments_nn3,price))+
geom_jitter(height=0.5,width=0.5)+
xlim(0,7500)+
ylim(0,1000)+
labs(x="Avg. Distance to 3 Landmarks (m)", y="Nightly Rate",
title = "Location vs. Price",
subtitle = "Amsterdam Airbnbs")+
geom_point(data=full_listings.sf,mapping=aes(monuments_nn3,price))+
geom_smooth(method="lm")+
stat_cor(method="pearson",
label.x=4500,
label.y=950) +
labs(x="Distance From Monuments", y="Nightly Rate",
title = "Monuments in Vicinity vs. Price",
subtitle = "Amsterdam Airbnbs")+
theme_minimal()
ggplot()+
geom_histogram(data=full_listings.sf,mapping=aes(price)) +
labs(x="Nightly Rate", y="Frequency",
title = "Distribution of Nightly Rate Prices",
subtitle = "Amsterdam Airbnbs")+
theme_minimal()
ggplot()+
geom_histogram(data=full_listings.sf,mapping=aes(log10(price))) +
labs(x="Nightly Rate", y="Frequency",
title = "Distribution of Logarithmic Transformation",
subtitle = "Amsterdam Airbnbs")+
theme_minimal()
